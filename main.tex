\documentclass[12pt, a4paper]{article}

\usepackage{cmap}					
\usepackage[T2A]{fontenc}		
\usepackage[utf8]{inputenc}			
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage{latexsym}
\title{Иерархическая кластеризация}


\begin{document}
\maketitle
Иерархическая кластеризация выводит иерархию, структуру, которая является более информативной, чем неструктурированный набор кластеров, возвращаемых плоской кластеризацией. Иерархическая кластеризация не требует заранее определять количество кластеров, и большинство популярных иерархических алгоритмов является детерминированными. Наиболее распространенные алгоритмы иерархической кластеризации имеют сложность, которая является по меньшей мере квадратичной по количеству документов по сравнению с линейной сложностью K-средних и EM-алгоритма.

Существует два подхода решения задачи иерархической кластеризации – восходящий и нисходящий. Восходящий алгоритм присваивает каждому образцу отдельный кластер, 
а затем объединяет пары наиболее похожих друг на друга кластеров в один, пока не получит кластер со всеми объектами внутри. Нисходящий алгоритм наоборот: 
начинает с большого кластера и далее рекурсивно разделяет кластеры, пока в каждом кластере не будет по одному объекту.
Часто иерархическую кластеризацию представляют в форме дендрограм, 
где схожие объекты содержатся в одинаковых ветвях. Для перевода результата иерархической кластеризации в плоский вид необходимо сделать разрез на определенном уровне. Существует несколько правил для выбора уровня разреза:

\begin{itemize}
\item Совершать разрез на данном уровне схожести.
\item Сделать разрез там, где разница между двумя уровнями схожести, в случае разреза, будет максимальной.
\item Зафиксировать строгое количество K кластеров и выбрать соответствующий уровень для разделения.
\end{itemize}
   
\section*{Восходящая кластеризация}
Для начала стоит ввести такое понятие, как расстояние между точками. Существует несколько способов определения расстояний:
\begin{itemize}


\item евклидово расстояние:

\[
\||a-b||_2 = \sqrt{\sum_i (a_i-b_i)^2}
\]
\item квадрат евклидова расстояния, являющийся всего лишь возведением в квадрат предыдущей формулы:
\[
\||a-b||_2^2 = \sum_i (a_i-b_i)^2
\]
\item манхэттенская метрика, в которой расстояние между точками является просто суммой модулей разностей их координат:
\[
\||a-b||_1 = \sum_i |a_i-b_i|
\]
\item максимальное расстояние, являющееся просто нахождением максимума модуля между двумя любыми точками:
\[
\||a-b||_\infty = \max_i |a_i-b_i|
\]
\item и расстояние Махаланобиса – более сложное определение расстояния:
\[
\||a-b|| = \sqrt {(a-b)^T S^{-1} (a-b)}
\]
где a и b - многомерные векторы, а S - матрица ковариации
\end{itemize}

Также существует несколько алгоритмов для определения схожести кластеров:

\begin{itemize}
\item Односвязная кластеризация. В этом подходе схожесть двух кластеров определяется как схожесть их двух наиболее похожих друг на друга элементов:
\[
\ SIM-SL(\omega_i, \omega_j) =  \min_{i} d(s_{n},s_{m})
\]
где d - некоторая функция схожести. При таком подходе уделяется внимание лишь тем областям, в которых кластеры наиболее близки и игнорируются другие части и общая структура
\item Полносвязная кластеризация. В этом подходе схожесть двух кластеров определяется как схожесть их двух наиболее различающихся элементов:
\[
\ SIM-CL(\omega_i,\omega_j) =  \max_{i} d(s_{n},s_{m})
\]
Данный подход позволяет создавать компактные кластеры; чувствителен к выбросам.
\item Среднегрупповая кластеризация. В данном алгоритме учитывается схожесть всех образцов в кластерах, подсчитывая величину:
\[
\ SIM-AL(\omega_i,\omega_j) = \frac{1}{(N_{i} + N_{j})(N_{i} + N_{j} - 1)}{\mit\Sigma}_{{s_{m}}\ni\omega_i\cup\omega_j}{\mit\Sigma}_{{s_{n}}\ni\omega_i\cup\omega_j}
d(s_{m},s_{n})
\]
Такой подход позволяет получить когерентные кластеры
\item Метод центроидов. В этом подходе схожесть двух кластеров определяется как схожесть их центроидов, причем за функцию расстояния берется евклидово расстояние:
\[
\ SIM-C(\omega_i,\omega_j) =||\mu(w_i),\mu(w_j)||
\]
\end{itemize}

\section*{Нисходящая кластеризация}

Дивизимные или нисходящие алгоритмы кластеризации разделяют один большой кластер на мелкие, до тех пор, пока в каждом кластере не останется по одному образцу. Для перевода иерархической кластеризации в плоскую, необходимо сделать разрез на каком-то уровне дендрограмы. 

Правила для выбора уровня разреза:
\begin{itemize} 
\item Зафиксировать количество кластеров.


\item Совершать разрез на определенном уровне дендрограмы. 


\item Совершать разрез, когда разница схожести между уровнями максимальна. 
\end{itemize}

Алгоритм выполняет следующие шаги:
\begin{enumerate}


\item Присвоить всем объектам один кластер.


\item Найти объект, который похож меньше всего на остальные и отделить его в отельный кластер.


\item В исходном кластере подсчитать среднюю схожесть с остальными объектами кластера и вычесть схожесть данного объекта с образцами в новом кластере. В случае, если величина отрицательна, этот объект переносится в новый кластер. В качестве метрики схожести можно использовать евклидово расстояние.
\[
d(p, q) = \sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + \cdots + (p_n - q_n)^2}
\]

\item Повторить предыдущий шаг до тех пор, пока не останется объектов с отрицательной разностью.



\item Повторить шаги 2-4 для кластеров с наибольшим диаметром.
\[
diam = \max_{s_m, s_n} d(s_m, s_n)
\]
         
         
\item Повторить шаги 2-5 до тех пор, пока каждый объект не будет соответствовать отдельному кластеру.
\end{enumerate}

\end{document}
